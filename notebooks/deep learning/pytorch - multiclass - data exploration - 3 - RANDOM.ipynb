{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f221d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdc1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be474b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "\n",
    "# from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72438673",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data = json.load(open(str(Path.home()) + '/kaggle.json', 'r'))\n",
    "KAGGLE_USERNAME = kaggle_data['username']\n",
    "KAGGLE_KEY = kaggle_data['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd00500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported access to kaggle\n"
     ]
    }
   ],
   "source": [
    "if KAGGLE_KEY and KAGGLE_USERNAME: print('Successfully imported access to kaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8bd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = KAGGLE_USERNAME\n",
    "os.environ['KAGGLE_KEY'] = KAGGLE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bd02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510eeee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset will be downloaded as zip under the current directory\n",
      "Downloading sewerpointclouds.zip to /home/nelth/WORKSPACE/template-nn/notebooks\n",
      " 96%|███████████████████████████████████████▏ | 177M/185M [00:01<00:00, 119MB/s]\n",
      "100%|█████████████████████████████████████████| 185M/185M [00:01<00:00, 114MB/s]\n"
     ]
    }
   ],
   "source": [
    "print('Dataset will be downloaded as zip under the current directory')\n",
    "!kaggle datasets download -d aalborguniversity/sewerpointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a33e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data\r\n",
      "'fastai - multilabel classification.ipynb'\r\n",
      "'from scratch - kaggle dataset download.ipynb'\r\n",
      " outputs\r\n",
      "'pytorch - multiclass - data exploration - 1 - boats.ipynb'\r\n",
      "'pytorch - multiclass - data exploration - 2 - shape.ipynb'\r\n",
      "'pytorch - multiclass - data exploration - 3 - stanford cars.ipynb'\r\n",
      "'pytorch - multiclass - model creation - 1 - boats.ipynb'\r\n",
      "'pytorch - multiclass - model creation - 2 - shape.ipynb'\r\n",
      "'pytorch - multiclass - model creation - 3 - stanford cars.ipynb'\r\n",
      " resnet50-transfer.pt\r\n",
      " resnet50-transfer.pth\r\n",
      " sewerpointclouds.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7690f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3784ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  sewerpointclouds.zip\n",
      "  inflating: images/data_loading.py  \n",
      "  inflating: images/testing_pointcloud_hdf5_real.h5  \n",
      "  inflating: images/testing_pointcloud_hdf5_synthetic.h5  \n",
      "  inflating: images/training_pointcloud_hdf5_real.h5  \n",
      "  inflating: images/training_pointcloud_hdf5_synthetic.h5  \n"
     ]
    }
   ],
   "source": [
    "!unzip *.zip -d images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865435bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d39c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "821661dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filepath: ./images/training_pointcloud_hdf5_synthetic.h5\n",
      "[Training Data]\n",
      "Data Shape: (10800, 1024, 3) | Type: float32\n",
      "Label Shape: (10800,) | Type: int64\n",
      "Labels: [0 1 2 3] | Counts: [5365 1811 1822 1802]\n",
      "\n",
      "\n",
      "Filepath: ./images/training_pointcloud_hdf5_synthetic.h5\n",
      "[Validation Data]\n",
      "Data Shape: (2700, 1024, 3) | Type: float32\n",
      "Label Shape: (2700,) | Type: int64\n",
      "Labels: [0 1 2 3] | Counts: [1385  439  428  448]\n",
      "\n",
      "\n",
      "Filepath: ./images/training_pointcloud_hdf5_real.h5\n",
      "[Training Data]\n",
      "Data Shape: (274, 1024, 3) | Type: float32\n",
      "Label Shape: (274,) | Type: int64\n",
      "Labels: [0 1 2 3] | Counts: [140  45  45  44]\n",
      "\n",
      "\n",
      "Filepath: ./images/training_pointcloud_hdf5_real.h5\n",
      "[Validation Data]\n",
      "Data Shape: (68, 1024, 3) | Type: float32\n",
      "Label Shape: (68,) | Type: int64\n",
      "Labels: [0 1 2 3] | Counts: [31 12 12 13]\n",
      "\n",
      "\n",
      "Filepath: ./images/testing_pointcloud_hdf5_synthetic.h5\n",
      "[Testing Data]\n",
      "Data Shape: (2700, 1024, 3) | Type: float32\n",
      "Label Shape: (2700,) | Type: int64\n",
      "Labels: [0 1 2 3] | Counts: [1350  450  450  450]\n",
      "\n",
      "\n",
      "Filepath: ./images/testing_pointcloud_hdf5_real.h5\n",
      "[Testing Data]\n",
      "Data Shape: (485, 1024, 3) | Type: float32\n",
      "Label Shape: (485,) | Type: int64\n",
      "Labels: [0 1 2 3] | Counts: [244  85  76  80]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_lidar_data():\n",
    "    import os\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    dataDir = \".\"\n",
    "    hdf5Files = [\"training_pointcloud_hdf5\", \"testing_pointcloud_hdf5\"]\n",
    "    dataTypes = [\"synthetic\", \"real\"]\n",
    "    partitions = [\"Training\", \"Validation\"]\n",
    "\n",
    "    classLabels = {0:\"Normal\", 1:\"Displacement\", 2:\"Brick\", 3:\"Rubber Ring\"}\n",
    "\n",
    "\n",
    "    for h5 in hdf5Files:\n",
    "        for dt in dataTypes:\n",
    "            path = os.path.join(dataDir, \"{}_{}.h5\".format('images/'+ h5, dt))\n",
    "\n",
    "            with h5py.File(path, 'r') as hdf:          \n",
    "                if h5 == \"training_pointcloud_hdf5\":\n",
    "                    partitions = [\"Training\", \"Validation\"]\n",
    "                else:\n",
    "                    partitions = [\"Testing\"]\n",
    "\n",
    "                for partition in partitions:\n",
    "                    data = np.asarray(hdf[f'{partition}/PointClouds'][:])\n",
    "                    labels = np.asarray(hdf[f'{partition}/Labels'][:])\n",
    "                    uniqueLabels, uniqueCounts = np.unique(labels, return_counts = True)\n",
    "\n",
    "                    print(f'\\nFilepath: {path}')\n",
    "                    print(f'[{partition} Data]')\n",
    "                    print(f'Data Shape: {data.shape} | Type: {data[0].dtype}')\n",
    "                    print(f'Label Shape: {labels.shape} | Type: {labels[0].dtype}')\n",
    "                    print(f'Labels: {uniqueLabels} | Counts: {uniqueCounts}\\n')\n",
    "                    \n",
    "print_lidar_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae66ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /home/nelth/anaconda3/envs/airbnb-furniture-finder/lib/python3.9/site-packages (3.6.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /home/nelth/anaconda3/envs/airbnb-furniture-finder/lib/python3.9/site-packages (from tables) (1.19.5)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /home/nelth/anaconda3/envs/airbnb-furniture-finder/lib/python3.9/site-packages (from tables) (2.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ef757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import HDFStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "066a039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5e1e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: images/training_pointcloud_hdf5_real.h5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf = HDFStore('images/training_pointcloud_hdf5_real.h5'); hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee7099ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: images/testing_pointcloud_hdf5_real.h5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf = HDFStore('images/testing_pointcloud_hdf5_real.h5'); hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aed924cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1139e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hdf.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d852a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named Training Data in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32311/1936210555.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/airbnb-furniture-finder/lib/python3.9/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mget_storer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No object named {key} in the file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No object named Training Data in the file'"
     ]
    }
   ],
   "source": [
    "hdf.get_storer('Training Data').table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9feaf449",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named Normal in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32311/464993195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/airbnb-furniture-finder/lib/python3.9/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mget_storer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No object named {key} in the file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No object named Normal in the file'"
     ]
    }
   ],
   "source": [
    "hdf.get_storer('Normal').table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "truc = pd.read_hdf('images/training_pointcloud_hdf5_real.h5')\n",
    "truc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a078f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "truc = pd.read_hdf('images/training_pointcloud_hdf5_synthetic.h5')\n",
    "truc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce749dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5eb51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3722ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c30a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePATH = f\"images/cars_train/\"\n",
    "ImagePATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e05af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = glob(ImagePATH+\"*\")\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223132ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePATH = f\"images/cars_test/\"\n",
    "ImagePATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf = pd.DataFrame()\n",
    "for cat in categories:\n",
    "    files = glob(cat+\"/*\")\n",
    "    print(files)\n",
    "    tempdf = pd.DataFrame({ 'filepath':files, 'category':cat.split(\"/\")[-1] })\n",
    "    print(tempdf)\n",
    "    filedf = pd.concat([filedf,tempdf])\n",
    "filedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af302d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gby_cnt = filedf.groupby(\"category\").aggregate('count').rename(columns = {'filepath':'cnt'}).reset_index().sort_values(by='cnt',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f04b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(gby_cnt, x='category', y='cnt', color='category', title='Counts from Each Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f551899",
   "metadata": {},
   "outputs": [],
   "source": [
    "gby_cnt.to_csv(f\"outputs/category_counts.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7560412",
   "metadata": {},
   "source": [
    "## Img exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419516d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "for i in range(16):\n",
    "    path = filedf.sample(1)['filepath'].values[0]\n",
    "    category = path.split(\"/\")[1]\n",
    "    ex_img = Image.open(path)\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    ax.annotate(category, xy=(0.65, 0.9), xycoords=\"axes fraction\",weight='bold',size=20)\n",
    "    ax.imshow(ex_img)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e83f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_cats = gby_cnt[gby_cnt['cnt'] >=40]['category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf = filedf[filedf['category'].isin(focus_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84453c2",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(\n",
    "        filedf, filedf['category'],stratify=filedf['category'], test_size=0.4)\n",
    "\n",
    "X_test, X_val, _, _ = train_test_split(\n",
    "        X_test, X_test['category'], stratify=X_test['category'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['type'] = 'train'\n",
    "X_val['type'] = 'val'\n",
    "X_test['type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = pd.concat([X_train, X_test, X_val])\n",
    "fulldf['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving data to train/test/val folder\n",
    "!rm -rf data\n",
    "!mkdir data\n",
    "!rm -rf data/\n",
    "!rm -rf data/train\n",
    "!rm -rf data/test\n",
    "!rm -rf data/val\n",
    "!mkdir data/\n",
    "!mkdir data/train\n",
    "!mkdir data/test\n",
    "!mkdir data/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in fulldf.category.unique():\n",
    "    os.system(f\"mkdir data/train/'{cat}'\") \n",
    "    os.system(f\"mkdir data/test/'{cat}'\") \n",
    "    os.system(f\"mkdir data/val/'{cat}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in fulldf.iterrows():\n",
    "    # Boat category\n",
    "    cat = row['category']\n",
    "    # section is train,val or test\n",
    "    section = row['type']\n",
    "    # input filepath to copy\n",
    "    ipath = row['filepath']\n",
    "    # output filepath to pastes\n",
    "    opath = ipath.replace(f\"{ImagePATH}\", f\"data/{section}/\")\n",
    "    # running the cp command\n",
    "    os.system(f\"cp '{ipath}' '{opath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060129ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
